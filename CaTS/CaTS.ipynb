{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY8UqOYWtywF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, Subset, Sampler\n",
        "from PIL import Image\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import itertools\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import math\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "def seed_everything(seed=1337):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything()\n",
        "\n",
        "config = {\n",
        "    \"image_size\": 256,\n",
        "    \"batch_size\": 16,\n",
        "    \"labeled_bs_ratio\": 0.5,\n",
        "    \"num_classes\": 2,\n",
        "    \"base_lr\": 1e-3,\n",
        "    \"weight_decay\": 1e-2,\n",
        "    \"epochs\": 100,\n",
        "    \"ema_decay\": 0.99,\n",
        "    \"consistency_lambda\": 1.0,\n",
        "    \"confound_lambda\": 1.0,\n",
        "    \"backdoor_lambda\": 1.0,\n",
        "    \"n_transformer_layers\": 6,\n",
        "    \"n_causal_queries\": 8,\n",
        "    \"transformer_embed_dim\": 2048,\n",
        "    \"transformer_nhead\": 8,\n",
        "    \"transformer_ff_dim\": 2048,\n",
        "    \"memory_bank_size\": 1024,\n",
        "    \"train_test_split_ratio\": 0.8,\n",
        "    \"labeled_unlabeled_split_ratio\": 0.2,\n",
        "    \"seed\": 1337,\n",
        "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
        "    \"data_root\": \"INPUT PATH\",\n",
        "    \"output_dir\": \"OUTPUT PATH\"\n",
        "}\n",
        "\n",
        "config[\"labeled_bs\"] = int(config[\"batch_size\"] * config[\"labeled_bs_ratio\"])\n",
        "\n",
        "if not os.path.exists('../pcos_dataset.csv'):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "    class_map = {'PCOS_positive': 1, 'PCOS_negative': 0}\n",
        "    positive_folder = os.path.join(config[\"data_root\"], '../PCOSGen-train/images')\n",
        "    negative_folder = os.path.join(config[\"data_root\"], '../PCOSGen-train/images')\n",
        "\n",
        "    all_files = [f for f in os.listdir(positive_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    for filename in all_files:\n",
        "        full_path = os.path.join(positive_folder, filename)\n",
        "        if 'pco' in filename.lower() or 'polycystic' in filename.lower() or 'infected' in filename.lower():\n",
        "             if os.path.exists(full_path):\n",
        "                 image_paths.append(full_path)\n",
        "                 labels.append(1)\n",
        "        elif 'normal' in filename.lower() or 'notinfected' in filename.lower():\n",
        "            if os.path.exists(full_path):\n",
        "                image_paths.append(full_path)\n",
        "                labels.append(0)\n",
        "\n",
        "    if not image_paths:\n",
        "         raise FileNotFoundError(\"No images found. Check data_root and folder structure.\")\n",
        "\n",
        "    df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
        "    df.to_csv('../pcos_dataset.csv', index=False)\n",
        "\n",
        "weak_transform = transforms.Compose([\n",
        "    transforms.Resize((config[\"image_size\"], config[\"image_size\"])),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(config[\"image_size\"], padding=int(config[\"image_size\"]*0.125), padding_mode='reflect'),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "strong_transform = transforms.Compose([\n",
        "    transforms.Resize((config[\"image_size\"], config[\"image_size\"])),\n",
        "    transforms.RandAugment(num_ops=2, magnitude=10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((config[\"image_size\"], config[\"image_size\"])),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class PCOSImageDataset(Dataset):\n",
        "    def __init__(self, csv_file, weak_transform=None, strong_transform=None, val_transform=None, mode='train'):\n",
        "        self.dataframe = pd.read_csv(csv_file)\n",
        "        self.weak_transform = weak_transform\n",
        "        self.strong_transform = strong_transform\n",
        "        self.val_transform = val_transform\n",
        "        self.mode = mode\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.dataframe.iloc[idx]['image_path']\n",
        "        label = torch.tensor(self.dataframe.iloc[idx]['label'], dtype=torch.long)\n",
        "\n",
        "        try:\n",
        "            if not os.path.exists(img_path):\n",
        "                 placeholder_img = torch.zeros((3, config[\"image_size\"], config[\"image_size\"]))\n",
        "                 if self.mode == 'train':\n",
        "                    return placeholder_img, placeholder_img, torch.tensor(-1, dtype=torch.long)\n",
        "                 else:\n",
        "                    return placeholder_img, torch.tensor(-1, dtype=torch.long)\n",
        "\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "            if self.mode == 'train':\n",
        "                img_weak = self.weak_transform(image)\n",
        "                img_strong = self.strong_transform(image)\n",
        "                return img_weak, img_strong, label\n",
        "            else:\n",
        "                img_val = self.val_transform(image)\n",
        "                return img_val, label\n",
        "        except Exception as e:\n",
        "                placeholder_img = torch.zeros((3, config[\"image_size\"], config[\"image_size\"]))\n",
        "                if self.mode == 'train':\n",
        "                    return placeholder_img, placeholder_img, torch.tensor(-1, dtype=torch.long)\n",
        "                else:\n",
        "                    return placeholder_img, torch.tensor(-1, dtype=torch.long)\n",
        "\n",
        "full_df = pd.read_csv('../pcos_dataset.csv')\n",
        "\n",
        "train_val_indices, test_indices = train_test_split(\n",
        "    range(len(full_df)),\n",
        "    test_size=1.0 - config[\"train_test_split_ratio\"],\n",
        "    stratify=full_df['label'],\n",
        "    random_state=config[\"seed\"]\n",
        ")\n",
        "\n",
        "train_indices, val_indices = train_test_split(\n",
        "    train_val_indices,\n",
        "    test_size=0.2,\n",
        "    stratify=full_df.iloc[train_val_indices]['label'],\n",
        "    random_state=config[\"seed\"]\n",
        ")\n",
        "\n",
        "labeled_indices, unlabeled_indices = train_test_split(\n",
        "    train_indices,\n",
        "    test_size=1.0 - config[\"labeled_unlabeled_split_ratio\"],\n",
        "    stratify=full_df.iloc[train_indices]['label'],\n",
        "    random_state=config[\"seed\"]\n",
        ")\n",
        "\n",
        "train_dataset = PCOSImageDataset(csv_file='../pcos_dataset.csv', weak_transform=weak_transform, strong_transform=strong_transform, mode='train')\n",
        "val_dataset = PCOSImageDataset(csv_file='../pcos_dataset.csv', val_transform=val_transform, mode='val')\n",
        "test_dataset = PCOSImageDataset(csv_file='../pcos_dataset.csv', val_transform=val_transform, mode='test')\n",
        "\n",
        "val_subset = Subset(val_dataset, val_indices)\n",
        "test_subset = Subset(test_dataset, test_indices)\n",
        "\n",
        "class TwoStreamBatchSampler(Sampler):\n",
        "    def __init__(self, primary_indices, secondary_indices, batch_size, secondary_batch_size):\n",
        "        self.primary_indices = primary_indices\n",
        "        self.secondary_indices = secondary_indices\n",
        "        self.secondary_batch_size = secondary_batch_size\n",
        "        self.primary_batch_size = batch_size - secondary_batch_size\n",
        "\n",
        "        assert len(self.primary_indices) >= self.primary_batch_size > 0\n",
        "        assert len(self.secondary_indices) >= self.secondary_batch_size >= 0\n",
        "\n",
        "    def __iter__(self):\n",
        "        primary_iter = iterate_once(self.primary_indices)\n",
        "        secondary_iter = iterate_eternally(self.secondary_indices)\n",
        "        len_primary_batches = len(self.primary_indices) // self.primary_batch_size\n",
        "        len_secondary_batches = len(self.secondary_indices) // self.secondary_batch_size if self.secondary_batch_size > 0 else float('inf')\n",
        "\n",
        "        num_batches = min(len_primary_batches, len_secondary_batches)\n",
        "        if self.secondary_batch_size == 0 :\n",
        "            num_batches = len_primary_batches\n",
        "\n",
        "        combined_iter = (\n",
        "            primary_batch + secondary_batch\n",
        "            for (primary_batch, secondary_batch)\n",
        "            in zip(grouper(primary_iter, self.primary_batch_size),\n",
        "                    grouper(secondary_iter, self.secondary_batch_size))\n",
        "        )\n",
        "\n",
        "        if self.secondary_batch_size > 0:\n",
        "            return itertools.islice(combined_iter, num_batches)\n",
        "        else:\n",
        "            primary_only_iter = (primary_batch for primary_batch in grouper(primary_iter, self.primary_batch_size))\n",
        "            return itertools.islice(primary_only_iter, num_batches)\n",
        "\n",
        "    def __len__(self):\n",
        "        len_primary_batches = len(self.primary_indices) // self.primary_batch_size\n",
        "        if self.secondary_batch_size == 0:\n",
        "            return len_primary_batches\n",
        "        len_secondary_batches = len(self.secondary_indices) // self.secondary_batch_size if self.secondary_batch_size > 0 else float('inf')\n",
        "        return min(len_primary_batches, len_secondary_batches)\n",
        "\n",
        "def iterate_once(iterable):\n",
        "    return np.random.permutation(iterable)\n",
        "\n",
        "def iterate_eternally(indices):\n",
        "    def infinite_shuffles():\n",
        "        while True:\n",
        "            yield np.random.permutation(indices)\n",
        "    return itertools.chain.from_iterable(infinite_shuffles())\n",
        "\n",
        "def grouper(iterable, n):\n",
        "    args = [iter(iterable)] * n\n",
        "    return zip(*args)\n",
        "\n",
        "train_batch_sampler = TwoStreamBatchSampler(\n",
        "    labeled_indices, unlabeled_indices, config[\"batch_size\"], config[\"batch_size\"] - config[\"labeled_bs\"]\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_sampler=train_batch_sampler, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_subset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "class PositionAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(PositionAttention, self).__init__()\n",
        "        reduced_channels = max(in_channels // 8, 64)\n",
        "        self.query_conv = nn.Conv2d(in_channels, reduced_channels, kernel_size=1)\n",
        "        self.key_conv = nn.Conv2d(in_channels, reduced_channels, kernel_size=1)\n",
        "        self.value_conv = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, C, height, width = x.size()\n",
        "        proj_query = self.query_conv(x).view(batch_size, -1, width * height).permute(0, 2, 1)\n",
        "        proj_key = self.key_conv(x).view(batch_size, -1, width * height)\n",
        "        energy = torch.bmm(proj_query, proj_key)\n",
        "        attention = self.softmax(energy)\n",
        "        proj_value = self.value_conv(x).view(batch_size, -1, width * height)\n",
        "\n",
        "        out = torch.bmm(proj_value, attention.permute(0, 2, 1))\n",
        "        out = out.view(batch_size, C, height, width)\n",
        "\n",
        "        out = self.gamma * out + x\n",
        "        return out\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.gamma = nn.Parameter(torch.zeros(1))\n",
        "        self.softmax  = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        batch_size, C, height, width = x.size()\n",
        "        proj_query = x.view(batch_size, C, -1)\n",
        "        proj_key = x.view(batch_size, C, -1).permute(0, 2, 1)\n",
        "        energy = torch.bmm(proj_query, proj_key)\n",
        "        attention = self.softmax(energy)\n",
        "        proj_value = x.view(batch_size, C, -1)\n",
        "\n",
        "        out = torch.bmm(attention, proj_value)\n",
        "        out = out.view(batch_size, C, height, width)\n",
        "\n",
        "        out = self.gamma * out + x\n",
        "        return out\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self, in_channels=2048, out_channels=1024):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.conv_ch = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.ch_attn = ChannelAttention(out_channels)\n",
        "\n",
        "        self.conv_pos = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.pos_attn = PositionAttention(out_channels)\n",
        "\n",
        "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.conv_gap = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "        self.conv_skip = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_ch = self.conv_ch(x)\n",
        "        x_ch_attn = self.ch_attn(x_ch)\n",
        "\n",
        "        x_pos = self.conv_pos(x)\n",
        "        x_pos_attn = self.pos_attn(x_pos)\n",
        "\n",
        "        branch1_out = self.relu(self.bn1(x_ch_attn + x_pos_attn))\n",
        "\n",
        "        x_gap = self.gap(x)\n",
        "        x_gap = self.conv_gap(x_gap)\n",
        "\n",
        "        x_skip = self.conv_skip(x)\n",
        "\n",
        "        branch2_out = self.relu(self.bn1(x_skip * x_gap.expand_as(x_skip) + x_skip))\n",
        "\n",
        "        out = torch.cat((branch1_out, branch2_out), dim=1)\n",
        "        return out\n",
        "\n",
        "class FixedPositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=64):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x\n",
        "\n",
        "class CausalDisentanglement(nn.Module):\n",
        "    def __init__(self, d_model, nhead, num_decoder_layers, dim_feedforward, n_queries):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_queries = n_queries\n",
        "\n",
        "        self.pos_encoder = FixedPositionalEncoding(d_model)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, batch_first=True)\n",
        "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
        "\n",
        "        self.causal_queries = nn.Parameter(torch.zeros(1, n_queries, d_model))\n",
        "\n",
        "    def forward(self, features):\n",
        "        B, C, H, W = features.shape\n",
        "        features_flat = features.flatten(2).permute(0, 2, 1)\n",
        "\n",
        "        features_pos = self.pos_encoder(features_flat)\n",
        "\n",
        "        queries = self.causal_queries.repeat(B, 1, 1)\n",
        "\n",
        "        causal_output = self.transformer_decoder(tgt=queries, memory=features_pos)\n",
        "\n",
        "        F_cau_avg = causal_output.mean(dim=1)\n",
        "\n",
        "        S_avg = features_pos.mean(dim=1)\n",
        "\n",
        "        F_con = S_avg - F_cau_avg\n",
        "\n",
        "        return F_cau_avg, F_con\n",
        "\n",
        "class MLPHead(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=512, out_dim=2, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(hidden_dim, out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x_intermediate = self.relu(x)\n",
        "        x = self.dropout(x_intermediate)\n",
        "        x_logits = self.fc2(x)\n",
        "        return x_intermediate, x_logits\n",
        "\n",
        "class CaTSModel(nn.Module):\n",
        "    def __init__(self, num_classes, n_transformer_layers, n_causal_queries,\n",
        "                 transformer_embed_dim, transformer_nhead, transformer_ff_dim, dropout=0.5):\n",
        "        super().__init__()\n",
        "        resnet = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V1)\n",
        "        self.backbone = nn.Sequential(*list(resnet.children())[:-2])\n",
        "        for param in self.backbone.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.backbone_out_channels = 2048\n",
        "\n",
        "        self.feature_extractor = FeatureExtractor(in_channels=self.backbone_out_channels, out_channels=self.backbone_out_channels // 2)\n",
        "        self.feature_extractor_out_channels = self.backbone_out_channels\n",
        "\n",
        "        self.causal_disentanglement = CausalDisentanglement(\n",
        "            d_model=self.feature_extractor_out_channels,\n",
        "            nhead=transformer_nhead,\n",
        "            num_decoder_layers=n_transformer_layers,\n",
        "            dim_feedforward=transformer_ff_dim,\n",
        "            n_queries=n_causal_queries\n",
        "        )\n",
        "        self.causal_out_dim = self.feature_extractor_out_channels\n",
        "\n",
        "        self.mlp_cau = MLPHead(in_dim=self.causal_out_dim, out_dim=num_classes, dropout=dropout)\n",
        "        self.mlp_con = MLPHead(in_dim=self.causal_out_dim, out_dim=num_classes, dropout=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.feature_extractor(x)\n",
        "        F_cau_vec, F_con_vec = self.causal_disentanglement(x)\n",
        "        eta_cau, mu_cau = self.mlp_cau(F_cau_vec)\n",
        "        eta_con, mu_con = self.mlp_con(F_con_vec)\n",
        "        return eta_cau, eta_con, mu_cau, mu_con\n",
        "\n",
        "causal_loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "kl_loss_fn = nn.KLDivLoss(reduction='batchmean')\n",
        "uniform_dist = torch.full((config[\"batch_size\"], config[\"num_classes\"]), 1.0 / config[\"num_classes\"]).to(config[\"device\"])\n",
        "\n",
        "def confound_loss_fn(mu_con_stu):\n",
        "    current_batch_size = mu_con_stu.shape[0]\n",
        "    if uniform_dist.shape[0] != current_batch_size:\n",
        "        u_dist = torch.full((current_batch_size, config[\"num_classes\"]), 1.0 / config[\"num_classes\"]).to(config[\"device\"])\n",
        "    else:\n",
        "        u_dist = uniform_dist[:current_batch_size]\n",
        "\n",
        "    log_softmax_mu_con = F.log_softmax(mu_con_stu, dim=1)\n",
        "    return kl_loss_fn(log_softmax_mu_con, u_dist)\n",
        "\n",
        "backdoor_loss_fn = nn.CrossEntropyLoss()\n",
        "confound_memory_bank = []\n",
        "memory_bank_labels = []\n",
        "\n",
        "def update_memory_bank(eta_con_stu_labeled, labels_labeled):\n",
        "    global confound_memory_bank, memory_bank_labels\n",
        "    confound_memory_bank.append(eta_con_stu_labeled.detach().cpu())\n",
        "    memory_bank_labels.append(labels_labeled.detach().cpu())\n",
        "    if len(confound_memory_bank) > config[\"memory_bank_size\"] // config[\"labeled_bs\"]:\n",
        "         confound_memory_bank.pop(0)\n",
        "         memory_bank_labels.pop(0)\n",
        "\n",
        "def sample_from_memory_bank(current_labels):\n",
        "    if not confound_memory_bank:\n",
        "        return None\n",
        "\n",
        "    all_eta_con = torch.cat(confound_memory_bank, dim=0)\n",
        "    all_labels = torch.cat(memory_bank_labels, dim=0)\n",
        "\n",
        "    sampled_eta_con = []\n",
        "    current_device = current_labels.device\n",
        "\n",
        "    for i in range(len(current_labels)):\n",
        "        label = current_labels[i].item()\n",
        "        eligible_indices = (all_labels == label).nonzero(as_tuple=True)[0]\n",
        "        if len(eligible_indices) > 0:\n",
        "            sampled_idx = random.choice(eligible_indices)\n",
        "            sampled_eta_con.append(all_eta_con[sampled_idx])\n",
        "        else:\n",
        "            if len(all_eta_con) > 0:\n",
        "                 sampled_idx = random.randrange(len(all_eta_con))\n",
        "                 sampled_eta_con.append(all_eta_con[sampled_idx])\n",
        "            else:\n",
        "                 sampled_eta_con.append(torch.zeros_like(all_eta_con[0]))\n",
        "\n",
        "    if not sampled_eta_con:\n",
        "         return None\n",
        "\n",
        "    return torch.stack(sampled_eta_con).to(current_device)\n",
        "\n",
        "consistency_loss_fn = nn.MSELoss()\n",
        "\n",
        "student_model = CaTSModel(\n",
        "    num_classes=config[\"num_classes\"],\n",
        "    n_transformer_layers=config[\"n_transformer_layers\"],\n",
        "    n_causal_queries=config[\"n_causal_queries\"],\n",
        "    transformer_embed_dim=config[\"transformer_embed_dim\"],\n",
        "    transformer_nhead=config[\"transformer_nhead\"],\n",
        "    transformer_ff_dim=config[\"transformer_ff_dim\"],\n",
        "    dropout=0.5\n",
        ").to(config[\"device\"])\n",
        "\n",
        "teacher_model = CaTSModel(\n",
        "    num_classes=config[\"num_classes\"],\n",
        "    n_transformer_layers=config[\"n_transformer_layers\"],\n",
        "    n_causal_queries=config[\"n_causal_queries\"],\n",
        "    transformer_embed_dim=config[\"transformer_embed_dim\"],\n",
        "    transformer_nhead=config[\"transformer_nhead\"],\n",
        "    transformer_ff_dim=config[\"transformer_ff_dim\"],\n",
        "    dropout=0.5\n",
        ").to(config[\"device\"])\n",
        "\n",
        "teacher_model.load_state_dict(student_model.state_dict())\n",
        "for param in teacher_model.parameters():\n",
        "    param.detach_()\n",
        "\n",
        "optimizer = optim.Adam(student_model.parameters(), lr=config[\"base_lr\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "def update_ema_variables(model, ema_model, alpha, global_step):\n",
        "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
        "    for ema_param, param in zip(ema_model.parameters(), model.parameters()):\n",
        "        ema_param.data.mul_(alpha).add_(param.data, alpha=1 - alpha)\n",
        "\n",
        "global_step = 0\n",
        "\n",
        "for epoch in range(config[\"epochs\"]):\n",
        "    student_model.train()\n",
        "    teacher_model.eval()\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['epochs']}\", leave=False)\n",
        "\n",
        "    for batch_idx, (img_weak, img_strong, labels) in enumerate(progress_bar):\n",
        "        img_weak = img_weak.to(config[\"device\"])\n",
        "        img_strong = img_strong.to(config[\"device\"])\n",
        "        labels = labels.to(config[\"device\"])\n",
        "\n",
        "        img_weak_lab, img_strong_lab = img_weak[:config[\"labeled_bs\"]], img_strong[:config[\"labeled_bs\"]]\n",
        "        img_weak_unlab, img_strong_unlab = img_weak[config[\"labeled_bs\"]:], img_strong[config[\"labeled_bs\"]:]\n",
        "        labels_lab = labels[:config[\"labeled_bs\"]]\n",
        "\n",
        "        loss_sup = torch.tensor(0.0).to(config[\"device\"])\n",
        "        loss_cau = torch.tensor(0.0).to(config[\"device\"])\n",
        "        loss_con = torch.tensor(0.0).to(config[\"device\"])\n",
        "        loss_bd = torch.tensor(0.0).to(config[\"device\"])\n",
        "\n",
        "        if config[\"labeled_bs\"] > 0:\n",
        "            eta_cau_stu_lab, eta_con_stu_lab, mu_cau_stu_lab, mu_con_stu_lab = student_model(img_weak_lab)\n",
        "            loss_cau = causal_loss_fn(mu_cau_stu_lab, labels_lab)\n",
        "            loss_con = confound_loss_fn(mu_con_stu_lab)\n",
        "            update_memory_bank(eta_con_stu_lab, labels_lab)\n",
        "            sampled_eta_con = sample_from_memory_bank(labels_lab)\n",
        "            if sampled_eta_con is not None and sampled_eta_con.shape[0] == eta_cau_stu_lab.shape[0]:\n",
        "                eta_cau_perturbed = eta_cau_stu_lab + sampled_eta_con\n",
        "                x_perturbed = student_model.mlp_cau.dropout(eta_cau_perturbed)\n",
        "                mu_cau_perturbed = student_model.mlp_cau.fc2(x_perturbed)\n",
        "                loss_bd = backdoor_loss_fn(mu_cau_perturbed, labels_lab)\n",
        "            else:\n",
        "                 loss_bd = torch.tensor(0.0).to(config[\"device\"])\n",
        "\n",
        "            loss_sup = loss_cau + config[\"confound_lambda\"] * loss_con + config[\"backdoor_lambda\"] * loss_bd\n",
        "\n",
        "        loss_cr = torch.tensor(0.0).to(config[\"device\"])\n",
        "        num_unlabeled = img_strong_unlab.shape[0]\n",
        "\n",
        "        if num_unlabeled > 0:\n",
        "            _, _, mu_cau_stu_unlab, _ = student_model(img_strong_unlab)\n",
        "            with torch.no_grad():\n",
        "                _, _, mu_cau_tea_unlab, _ = teacher_model(img_weak_unlab)\n",
        "            loss_cr = consistency_loss_fn(mu_cau_stu_unlab, mu_cau_tea_unlab)\n",
        "\n",
        "        total_loss = loss_sup + config[\"consistency_lambda\"] * loss_cr\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        update_ema_variables(student_model, teacher_model, config[\"ema_decay\"], global_step)\n",
        "        global_step += 1\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            'Loss': f\"{total_loss.item():.4f}\",\n",
        "            'L_cau': f\"{loss_cau.item():.4f}\" if config[\"labeled_bs\"] > 0 else \"N/A\",\n",
        "            'L_con': f\"{loss_con.item():.4f}\" if config[\"labeled_bs\"] > 0 else \"N/A\",\n",
        "            'L_bd': f\"{loss_bd.item():.4f}\" if config[\"labeled_bs\"] > 0 and sampled_eta_con is not None else \"N/A\",\n",
        "            'L_cr': f\"{loss_cr.item():.4f}\" if num_unlabeled > 0 else \"N/A\"\n",
        "        })\n",
        "\n",
        "    student_model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_preds_val = []\n",
        "    all_labels_val = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for img_val, labels_val in val_loader:\n",
        "            img_val, labels_val = img_val.to(config[\"device\"]), labels_val.to(config[\"device\"])\n",
        "            _, _, mu_cau_val, _ = student_model(img_val)\n",
        "            loss = causal_loss_fn(mu_cau_val, labels_val)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            preds = torch.argmax(mu_cau_val, dim=1)\n",
        "            all_preds_val.extend(preds.cpu().numpy())\n",
        "            all_labels_val.extend(labels_val.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_accuracy = accuracy_score(all_labels_val, all_preds_val)\n",
        "    val_precision = precision_score(all_labels_val, all_preds_val, average='binary', zero_division=0)\n",
        "    val_recall = recall_score(all_labels_val, all_preds_val, average='binary', zero_division=0)\n",
        "    val_f1 = f1_score(all_labels_val, all_preds_val, average='binary', zero_division=0)\n",
        "\n",
        "    print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_accuracy:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
        "\n",
        "student_model.eval()\n",
        "test_loss = 0.0\n",
        "all_preds_test = []\n",
        "all_labels_test = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img_test, labels_test in tqdm(test_loader, desc=\"Testing\"):\n",
        "        img_test, labels_test = img_test.to(config[\"device\"]), labels_test.to(config[\"device\"])\n",
        "\n",
        "        _, _, mu_cau_test, _ = student_model(img_test)\n",
        "\n",
        "        loss = causal_loss_fn(mu_cau_test, labels_test)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        preds = torch.argmax(mu_cau_test, dim=1)\n",
        "        all_preds_test.extend(preds.cpu().numpy())\n",
        "        all_labels_test.extend(labels_test.cpu().numpy())\n",
        "\n",
        "avg_test_loss = test_loss / len(test_loader)\n",
        "test_accuracy = accuracy_score(all_labels_test, all_preds_test)\n",
        "test_precision = precision_score(all_labels_test, all_preds_test, average='binary', zero_division=0)\n",
        "test_recall = recall_score(all_labels_test, all_preds_test, average='binary', zero_division=0)\n",
        "test_f1 = f1_score(all_labels_test, all_preds_test, average='binary', zero_division=0)\n",
        "\n",
        "print(\"\\n--- Test Set Results ---\")\n",
        "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Precision: {test_precision:.4f}\")\n",
        "print(f\"Recall: {test_recall:.4f}\")\n",
        "print(f\"F1 Score: {test_f1:.4f}\")"
      ]
    }
  ]
}